#
# Splunk app configuration file
#

[package]
id = TA-llm-command-scoring

[install]
is_configured = 0

[ui]
is_visible = 1
label = LLM Command-line Arg Malicious Score
setup_view = configuration

[launcher]
author = morethanyell
description = Queries a chosen AI language model to assess the potential risk of a command-line argument, returning a Likert-scale score that reflects the likelihood of malicious behavior.
version = 2.0.0
